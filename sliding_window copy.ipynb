{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6a6bd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Sequence\n",
    "import numpy as np\n",
    "\n",
    "from audio import get_clean_tensor,get_crunch_tensor,get_distortion_tensor,normalize_tensor\n",
    "from utilities import plot_waveform\n",
    "import styles_ranges as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e620d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "dry = get_clean_tensor()\n",
    "dry = normalize_tensor(dry)\n",
    "# plot_waveform(dry)\n",
    "crunch = get_crunch_tensor()\n",
    "# plot_waveform(crunch)\n",
    "distortion = get_distortion_tensor()\n",
    "# plot_waveform(distortion)\n",
    "\n",
    "seconds = 1\n",
    "test_split_ratio = 0.2\n",
    "\n",
    "train_time_seconds = 24\n",
    "val_time_seconds = 6\n",
    "train_samples_start = sr.POWER_CHORDS_RING_OUT_START\n",
    "train_samples_end = sr.CHORDS_ARPEGGIO_END\n",
    "\n",
    "val_samples_start = sr.PENTATONIC_FAST_START\n",
    "val_samples_end = sr.PENTATONIC_FAST_END\n",
    "\n",
    "x = dry[0]\n",
    "y = crunch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06a99092",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 400\n",
    "batch_size = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "479c3cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3380\n",
      "558\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.concat((torch.zeros(window_size - 1),x[train_samples_start:train_samples_end]))\n",
    "y_train = torch.concat((torch.zeros(window_size - 1),y[train_samples_start:train_samples_end]))\n",
    "\n",
    "x_val = torch.concat((torch.zeros(window_size - 1), x[val_samples_start:val_samples_end]))\n",
    "y_val = torch.concat((torch.zeros(window_size - 1), y[val_samples_start:val_samples_end]))\n",
    "\n",
    "batches = int(x_train.size(0) / batch_size)\n",
    "val_batches = int(x_val.size(0) / batch_size)\n",
    "print(batches)\n",
    "print(val_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9b801eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowArray(Sequence):\n",
    "        \n",
    "    def __init__(self, x, y, window_len, batch_size=32):\n",
    "        self.x = x\n",
    "        self.y = y[window_len-1:] \n",
    "        self.window_len = window_len\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (len(self.x) - self.window_len +1) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x_out = torch.stack([self.x[idx: idx+self.window_len] for idx in range(index*self.batch_size, (index+1)*self.batch_size)]).view(self.batch_size,self.window_len,-1)\n",
    "        y_out = self.y[index*self.batch_size:(index+1)*self.batch_size].view(-1,1)\n",
    "        return x_out, y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d07eb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1,2,3,4,5,6,7,8,9,10])\n",
    "b = torch.tensor([1,2,3,4,5,6,7,8,9,10])\n",
    "aw = WindowArray(a,b,6,3)\n",
    "abdl = DataLoader(aw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c1c6cf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_window = WindowArray(x_train,y_train,window_size,batch_size)\n",
    "val_window = WindowArray(x_val,y_val,window_size,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a1042906",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_window)\n",
    "val_loader = DataLoader(val_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00164d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = nn.Conv1d(1,16,11,1,5)\n",
    "c2 = nn.Conv1d(16,1,11,1,5)\n",
    "mp = nn.MaxPool1d(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0bb3daff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2000, 400, 1])\n",
      "torch.Size([1, 2000, 1])\n",
      "torch.Size([2000, 1, 80])\n",
      "torch.Size([2000, 1, 16])\n"
     ]
    }
   ],
   "source": [
    "for c,d in train_loader:\n",
    "    print(c.shape)\n",
    "    print(d.shape)\n",
    "    print(c2(mp(cnn(c[0].permute(0,2,1)))).shape)\n",
    "    print(mp(c2(mp(cnn(c[0].permute(0,2,1))))).shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cc01ac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, n_hidden, n_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=1,\n",
    "            out_channels=16,\n",
    "            kernel_size=11,\n",
    "            stride=1,\n",
    "            padding='same'\n",
    "        )\n",
    "\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.mp1 = nn.MaxPool1d(5)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(\n",
    "            in_channels=16,\n",
    "            out_channels=16,\n",
    "            kernel_size=11,\n",
    "            stride=1,\n",
    "            padding='same'\n",
    "        )\n",
    "\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.mp2 = nn.MaxPool1d(5)\n",
    "\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=16, \n",
    "            hidden_size=n_hidden,\n",
    "            num_layers=n_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(n_hidden,1)\n",
    "\n",
    "    def forward(self, x, state=None):\n",
    "        # print('forward start')\n",
    "        x = x.permute(0,2,1)\n",
    "        x = self.mp1(self.relu1(self.conv1(x)))\n",
    "        # print(x.shape)\n",
    "        x = self.mp2(self.relu2(self.conv2(x)))\n",
    "        # print(x.shape)\n",
    "        x = x.permute(0,2,1)\n",
    "        r_out, (h_s, c_s) = self.lstm(x, state)\n",
    "        # print(r_out.shape)\n",
    "        result = self.out(r_out[:,-1,:])\n",
    "        # print(result.shape)\n",
    "        # print('forward end')\n",
    "        return result, h_s, c_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a043177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss import ESRDCLoss\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "rnn = LSTM(128,2)\n",
    "optimizer = torch.optim.Adam(rnn.parameters(),lr=0.001)\n",
    "loss_fn = ESRDCLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d6d365e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_path = 'temporary/loss_scores.npy'\n",
    "val_loss_path = 'temporary/val_loss_scores.npy'\n",
    "means_path = 'temporary/mean_scores.npy'\n",
    "loss_scores = np.zeros(shape=(epochs,batches,1))\n",
    "val_loss_scores = np.zeros(shape=(epochs,val_batches,1))\n",
    "mean_scores = np.zeros(shape=(epochs,2))\n",
    "np.save(losses_path,loss_scores)\n",
    "np.save(val_loss_path,val_loss_scores)\n",
    "np.save(means_path,mean_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8527d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "batch:  289 / 3380  loss:  0.47223877906799316\r"
     ]
    }
   ],
   "source": [
    "epochs_losses = []\n",
    "for epoch in range(epochs):\n",
    "    print('epoch: %d' % epoch)\n",
    "    rnn.train()\n",
    "    losses = []\n",
    "    for i,(x_b,y_b) in enumerate(train_loader):\n",
    "        \n",
    "        print('batch: ', i+1, '/', batches, end='\\r')\n",
    "        pred,_,_ = rnn(x_b[0])\n",
    "        \n",
    "        loss = loss_fn(pred,y_b[0])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_value = loss.item()\n",
    "\n",
    "        losses.append(loss_value)\n",
    "        loss_scores[epoch,i,0] = loss_value\n",
    "        print('batch: ', i, '/', batches, ' loss: ', loss.item(), end='\\r')\n",
    "    print()\n",
    "    mean_loss = np.mean(losses)\n",
    "    mean_scores[epoch,0] = mean_loss\n",
    "    epochs_losses.append(mean_loss)\n",
    "    print(mean_loss)\n",
    "    np.save(losses_path,loss_scores)\n",
    "\n",
    "    rnn.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_losses = []\n",
    "        for j,(xv,yv) in enumerate(val_loader):\n",
    "            test,_,_ = rnn(xv[0])\n",
    "            val_loss = loss_fn(test,yv[0])\n",
    "            vl_value = val_loss.item()\n",
    "            val_losses.append(vl_value)\n",
    "            val_loss_scores[epoch,j,0] = vl_value\n",
    "\n",
    "        np.save(val_loss_path,val_loss_scores)\n",
    "\n",
    "        epoch_val_loss = np.mean(val_losses)\n",
    "        mean_scores[epoch,1] = epoch_val_loss\n",
    "        np.save(means_path,mean_scores)\n",
    "\n",
    "        print('val_loss: ', epoch_val_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
